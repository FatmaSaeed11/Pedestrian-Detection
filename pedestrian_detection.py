# -*- coding: utf-8 -*-
"""Pedestrian Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/pedestrian-detection-adb7a0ab-5b0b-40ac-acc9-61dfb2417fa2.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241119/auto/storage/goog4_request%26X-Goog-Date%3D20241119T113124Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7934f35c61fae7ba976048d9f4fd8ec8aba265d113bada15229284b6f58a88547825946af10d4ff1913ff09afd16016f0bec09d1112ff43a651cbc9a85d130533140ee8055145cb5202d8646b48c80be2581e02d266d28d22bebfa03fa6bcc67e0c2038d3462911a13454cf2f2e68c7098ac7001090dc6927d83df0093c2e01feefd849df310a740f1374124efb1151e781b9aed06dcc7f7f336b04212d6a1626d11673b085df5521b8f3ecb4ca66e613ef25baa457b0d4911bea884a70d16063b308f727fe3b7e0cc4b8f3b6ca8a23c44b6af08c69ef9d24989e7677c46f5ba878eb37df245db7b12bf79ed45ab4b60d057e52d8119057db74c8a780611eacc
"""

!pip install torch torchvision matplotlib

import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import functional as F
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

!wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip
!unzip PennFudanPed.zip



import os
import json
import torch
from PIL import Image

class PennFudanDataset(torch.utils.data.Dataset):
    def __init__(self, root, transforms=None):
        self.root = root
        self.transforms = transforms
        self.imgs = list(sorted(os.listdir(os.path.join(root, "PNGImages"))))
        self.masks = list(sorted(os.listdir(os.path.join(root, "PedMasks"))))

    def __getitem__(self, idx):
        img_path = os.path.join(self.root, "PNGImages", self.imgs[idx])
        mask_path = os.path.join(self.root, "PedMasks", self.masks[idx])
        img = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path)
        mask = np.array(mask)
        obj_ids = np.unique(mask)[1:]
        masks = mask == obj_ids[:, None, None]
        boxes = []
        for i in range(len(obj_ids)):
            pos = np.where(masks[i])
            xmin = np.min(pos[1])
            xmax = np.max(pos[1])
            ymin = np.min(pos[0])
            ymax = np.max(pos[0])
            boxes.append([xmin, ymin, xmax, ymax])

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.ones((len(obj_ids),), dtype=torch.int64)
        masks = torch.as_tensor(masks, dtype=torch.uint8)
        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((len(obj_ids),), dtype=torch.int64)

        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        target["masks"] = masks
        target["image_id"] = image_id
        target["area"] = area
        target["iscrowd"] = iscrowd

        if self.transforms:
            img = self.transforms(img)

        return img, target

    def __len__(self):
        return len(self.imgs)

dataset = PennFudanDataset("PennFudanPed")
img, target = dataset[0]
print("Image Shape:", np.array(img).shape)
print("Bounding Boxes:", target["boxes"])

model = fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

num_classes = 2  # 1 class (person) + background
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

from torch.utils.data import DataLoader

def collate_fn(batch):
    return tuple(zip(*batch))

data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)
optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)

num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    i = 0
    for images, targets in data_loader:
        images = [F.to_tensor(img) for img in images]
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()
        print(f"Epoch {epoch+1}, Loss: {losses.item()}")

test_img, _ = dataset[5]
model.eval()
with torch.no_grad():
    prediction = model([F.to_tensor(test_img)])

def plot_image_with_boxes(image, boxes):
    plt.imshow(image)
    for box in boxes:
        x_min, y_min, x_max, y_max = box
        plt.gca().add_patch(plt.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, linewidth=1, edgecolor='r', facecolor='none'))
    plt.show()

plot_image_with_boxes(test_img, prediction[0]['boxes'].cpu())